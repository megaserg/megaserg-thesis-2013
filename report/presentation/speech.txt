Здравствуйте меня зовут сергей я вам расскажу про свою дипломную работу на тему "схема сборки проектов с агрессивным переиспользованием порождений" которую я выполнял под руководством дмитрия юрьевича булычева.

Под сборкой проекта мы понимаем преобразование файлов высокого уровня, например, исходных файлов, в низкоуровневые артефакты - классфайлы, объектные файлы и так далее, то есть в узком смысле - компиляция.
При этом популярной оптимизацией процесса сборки является инкрементальная компиляция, когда переиспользуются результаты предыдущего сеанса компиляции, а компилируются только те файлы, которые с того момента были изменены, а также зависящие от них.
При этом информация о зависимостях и результаты компиляции сохраняются в специальном хранилище - кэше компиляции.
Однако в больших проектах, в которых принимает участие много разработчиков, случаются ситуации, когда у какого-то отдельного разработчика кэш компиляции устаревает, становится не соответствующим текущему состоянию копии проекта. Такое может произойти, когда кэш вообще пустой или когда программист в своей копии переключается на другую существенно отличающуюся ветку разработки. в таких случаях инкрементальная компиляция теряет свои преимущества и становится похожей на полную сборку. Однако можно воспользоваться тем, что разработчиков несколько, и переиспользовать их кэши, может быть, что-то докомпилировать и получить результат, идентичный результату полной сборки проекта.
Эта задача является родственной задаче инкрементальной компиляции, и у них есть общая сложность, которая состоит в том, что файлы зависят друг от друга, и зависят по-разному. Рассмотрим пример с инкрементальной компиляцией.

Мы в работе ориентировались в основном на язык Жава, однако полученные результаты достаточно общие, чтобы их можно применить и к другим языкам. В этом проекте три класса: вот класс А, он используется как тип в методе get класса Б, и этот метод вызывается в классе Ц. Пусть мы сделали полную сборку проекта. Если мы теперь изменим тело метода get, то нам нужно будет перекомпилировать только класс Б, потому что это изменение не затрагивает никакие другие классы. Но рассмотрим теперь такое изменение.

Класс А переместился в другой пакет. Интуитивно понятно, что придётся скомпилировать класс А и перекомпилировать класс Б. Однако на самом деле нужно перекомпилировать и класс Ц, потому что в классфайле этот вызов метода трансформируется в том числе в сигнатуру метода, которая включает в себя путь к классу А с точностью до пакета, а пакет поменялся. Понятно, что в реальном проекте классов может быть десятки тысяч, они друг от друга как-то зависят, и если мы хотим решать такие задачи, то нужно чётко понимать, какие файлы мы можем переиспользовать, а какие следует перекомпилировать.

Вот с этой светлой целью мы решили разработать формальную модель с аксиоматикой, отражающей ограничения реального мира, и в терминах этой модели сформулировать и решить задачи об инкрементальной компиляции и о переиспользовании порождений.

Компиляцию мы рассматриваем как функцию, которая на вход получает исходные файлы, а выдаёт некоторые атрибуты-порождения. Порождениями мы считаем сигнатуры методов, объявления полей, имена классов - это всё отдельные порождения. При этом компиляция всегда происходит в некотором контексте, состоящем из таких же порождений из предыдущих сеансов компиляции. Если какой-то вход в каком-то контексте компилируется успешно, то мы говорим, что функция на соответствующем входе определена; если компиляция неуспешная, то и функция не определена.

Для этой функции мы сконструировали набор аксиом. Например, мы запрещаем в исходном файле объявлять порождения, уже присутствующие в контексте. Также для каждого порождения из результата компиляции можно единственным образом указать тот исходный файл, в котором оно было определено.

Эти аксиомы говорят, что если какой-то вход в каком-то контексте успешно скомпилировался, то, возможно, можно выкинуть из контекста какие-то ненужные порождения, и результат компиляции не изменится. С другой стороны, если мы выкинем что-то нужное, то компиляция завершится с ошибкой. Как видно, аксиомы весьма естественные.

Далее, мы разбили множество всех порождений на классы. Порождения нулевого порядка - это те, которые зависят только от исходных файлов и никак не зависят от контекста. Порождения первого порядка - те, которые зависят только от исходных файлов и от порождений нулевого порядка из контекста. И так далее. Катого порядка - зависят только от исходных файлов и порождений до ка-минус-первого порядка из контекста. Если вспомнить пример, то в Жаве имена классов будут порождениями нулевого порядка, методы с классами или интерфейсами в качестве типов будут первого порядка, а вызовы таких методов - второго порядка. А выше второго порядка в Жаве ничего нет, вызовы - это уже неименованный участок кода.

Если мы компилируем один и тот же вход в разных контекстах, то справедливо ожидать, что получится разный результат. Однако во входе есть файлы, которые влияют на изменение результата, и те, которые не влияют. Чтобы их разделить, мы вводим понятие дифференциала. Дифференциал - это ровно те файлы, которые влияют на результат при переходе от одного контекста к другому. Его свойство таково, что результат компиляции дополнения к нему в старом и в новом контексте одинаков.

Рассмотрим теперь задачу инкрементальной компиляции. Пусть было состояние проекта сигма (вверху), и была сделана полная сборка проекта (внизу результат). Потом разработчик удалил файлы ро, и добавил другие файлы альфа, любое изменение можно так представить. Теперь он мог бы сделать полную сборку проекта, а мог бы использовать тот кэш, который у него есть для сигма без ро, скомпилировать добавку и объединить. Однако он получит совпадение с результатом полной сборки только до нулевого порядка, то есть будут совпадать только порождения нулевого порядка. Если нужно больше совпадений, ему придётся взять дифференциал от сигма без ро, то есть те файлы, которые зависят от альфа, и это даст совпадение до первого порядка. Если он возьмёт ещё и дифференциал от альфа, то получит совпадение до второго порядка, чего, напомню, для Жавы достаточно.

Вот теорема закрепляет это умозаключение. Она говорит, что нужно брать дифференциалы вот в таких контекстах, компилировать их в таких контекстах, и если потом всё объединить, то получится совпадение до второго порядка с результатом полной сборки, то есть в пустом контексте.

Вернёмся теперь к задаче переиспользования порождений. Пусть есть эн разработчиков, у каждого из которых есть своя копия проекта и свой локальный кэш компиляции. И есть эн-плюс-первый разработчик, у которого такое состояние, что его в полном виде ни у кого другого нет, но каждая его часть у кого-то присутствует, то есть оно представимо в виде объединения частей других копий. Тогда он может взять кусочки кэшей, соответствующие этим частям, и объединить их, получив совпадение до нулевого порядка с результатом полной сборки. Чтобы получить больше совпадений, нужно будет взять дифференциалы для каждой части относительно всех остальных частей, а потом дифференциалы для дополнений, чтобы получить совпадение до первого и до второго порядка соответственно.

Вот теорема говорит: действительно, возьмём такие и такие дифференциалы, скомпилируем так и так, получим совпадение до второго порядка с результатом компиляции в пустом контексте. Замечу, что обе теоремы получились конструктивными: они для каждого файла указывают, нужно ли его переиспользовать или перекомпилировать, и если перекомпилировать, то предъявляют контекст, в котором это нужно делать.

В результате мы сконструировали формальную модель с аксиоматикой, которая с одной стороны естественная, а с другой позволяет доказывать такие нетривиальные утверждения, как теоремы об инкрементальной компиляции и переиспользовании порождений. При этом теоремы получились конструктивные, и мы планируем на основе второй теоремы реализовать поддержку переиспользования кэшей в среде разработки интеллижей идея компании жетбрейнс.